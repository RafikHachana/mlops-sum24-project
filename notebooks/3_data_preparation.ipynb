{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from seaborn) (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mohammadshahin/uni/ms1-t3/mlops/project/mlops-sum24-project/venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is:  (71716, 39)\n",
      "     AppID                   Name  Release date Estimated owners  Peak CCU  \\\n",
      "0    20200       Galactic Bowling  Oct 21, 2008        0 - 20000         0   \n",
      "1   655370           Train Bandit  Oct 12, 2017        0 - 20000         0   \n",
      "2  1732930           Jolt Project  Nov 17, 2021        0 - 20000         0   \n",
      "3  1355720               Henosis™  Jul 23, 2020        0 - 20000         0   \n",
      "4  1139950  Two Weeks in Painland   Feb 3, 2020        0 - 20000         0   \n",
      "\n",
      "   Required age  Price  DLC count  \\\n",
      "0             0  19.99          0   \n",
      "1             0   0.99          0   \n",
      "2             0   4.99          0   \n",
      "3             0   5.99          0   \n",
      "4             0   0.00          0   \n",
      "\n",
      "                                      About the game  \\\n",
      "0  Galactic Bowling is an exaggerated and stylize...   \n",
      "1  THE LAW!! Looks to be a showdown atop a train....   \n",
      "2  Jolt Project: The army now has a new robotics ...   \n",
      "3  HENOSIS™ is a mysterious 2D Platform Puzzler w...   \n",
      "4  ABOUT THE GAME Play as a hacker who has arrang...   \n",
      "\n",
      "                                 Supported languages  ...  \\\n",
      "0                                        ['English']  ...   \n",
      "1  ['English', 'French', 'Italian', 'German', 'Sp...  ...   \n",
      "2                 ['English', 'Portuguese - Brazil']  ...   \n",
      "3  ['English', 'French', 'Italian', 'German', 'Sp...  ...   \n",
      "4                     ['English', 'Spanish - Spain']  ...   \n",
      "\n",
      "  Average playtime two weeks Median playtime forever  \\\n",
      "0                          0                       0   \n",
      "1                          0                       0   \n",
      "2                          0                       0   \n",
      "3                          0                       0   \n",
      "4                          0                       0   \n",
      "\n",
      "  Median playtime two weeks             Developers             Publishers  \\\n",
      "0                         0  Perpetual FX Creative  Perpetual FX Creative   \n",
      "1                         0           Rusty Moyher           Wild Rooster   \n",
      "2                         0          Campião Games          Campião Games   \n",
      "3                         0      Odd Critter Games      Odd Critter Games   \n",
      "4                         0          Unusual Games          Unusual Games   \n",
      "\n",
      "                                          Categories  \\\n",
      "0  Single-player,Multi-player,Steam Achievements,...   \n",
      "1  Single-player,Steam Achievements,Full controll...   \n",
      "2                                      Single-player   \n",
      "3              Single-player,Full controller support   \n",
      "4                   Single-player,Steam Achievements   \n",
      "\n",
      "                            Genres  \\\n",
      "0              Casual,Indie,Sports   \n",
      "1                     Action,Indie   \n",
      "2  Action,Adventure,Indie,Strategy   \n",
      "3           Adventure,Casual,Indie   \n",
      "4                  Adventure,Indie   \n",
      "\n",
      "                                                Tags  \\\n",
      "0                        Indie,Casual,Sports,Bowling   \n",
      "1  Indie,Action,Pixel Graphics,2D,Retro,Arcade,Sc...   \n",
      "2                                                NaN   \n",
      "3  2D Platformer,Atmospheric,Surreal,Mystery,Puzz...   \n",
      "4  Indie,Adventure,Nudity,Violent,Sexual Content,...   \n",
      "\n",
      "                                         Screenshots  \\\n",
      "0  https://cdn.akamai.steamstatic.com/steam/apps/...   \n",
      "1  https://cdn.akamai.steamstatic.com/steam/apps/...   \n",
      "2  https://cdn.akamai.steamstatic.com/steam/apps/...   \n",
      "3  https://cdn.akamai.steamstatic.com/steam/apps/...   \n",
      "4  https://cdn.akamai.steamstatic.com/steam/apps/...   \n",
      "\n",
      "                                              Movies  \n",
      "0  http://cdn.akamai.steamstatic.com/steam/apps/2...  \n",
      "1  http://cdn.akamai.steamstatic.com/steam/apps/2...  \n",
      "2  http://cdn.akamai.steamstatic.com/steam/apps/2...  \n",
      "3  http://cdn.akamai.steamstatic.com/steam/apps/2...  \n",
      "4  http://cdn.akamai.steamstatic.com/steam/apps/2...  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('../data/games.csv')\n",
    "print(\"The shape of the data is: \", data.shape)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  5236\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Single-player,Multi-player,Steam Achievements,Partial Controller Support',\n",
       " 'Single-player,Steam Achievements,Full controller support,Steam Leaderboards,Remote Play on Phone,Remote Play on Tablet,Remote Play on TV',\n",
       " 'Single-player',\n",
       " 'Single-player,Full controller support',\n",
       " 'Single-player,Steam Achievements']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include only non-null values\n",
    "col_name = 'Categories'\n",
    "col = list(data[col_name].dropna())[:5]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n",
    "# print(list(data[col_name].value_counts()))\n",
    "\n",
    "all_categories = []\n",
    "\n",
    "# apply a function to the values\n",
    "def clean_categories(categories):\n",
    "    if type(categories) is not str:\n",
    "        return []\n",
    "    # print(categories)\n",
    "    return categories.split(\",\")\n",
    "\n",
    "new_df = data[col_name].apply(clean_categories)\n",
    "# merge all the lists into one\n",
    "for categories in new_df:\n",
    "    all_categories.extend(categories)\n",
    "\n",
    "print(len(set(all_categories)))\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  2201\n",
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Casual,Indie,Sports',\n",
       " 'Action,Indie',\n",
       " 'Action,Adventure,Indie,Strategy',\n",
       " 'Adventure,Casual,Indie',\n",
       " 'Adventure,Indie']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include only non-null values\n",
    "col_name = 'Genres'\n",
    "col = list(data[col_name].dropna())[:5]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n",
    "# print(list(data[col_name].value_counts()))\n",
    "\n",
    "all_genres = []\n",
    "\n",
    "# apply a function to the values\n",
    "def clean_categories(categories):\n",
    "    if type(categories) is not str:\n",
    "        return []\n",
    "    # print(categories)\n",
    "    return categories.split(\",\")\n",
    "\n",
    "new_df = data[col_name].apply(clean_categories)\n",
    "# merge all the lists into one\n",
    "for categories in new_df:\n",
    "    all_genres.extend(categories)\n",
    "\n",
    "print(len(set(all_genres)))\n",
    "\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  50998\n",
      "446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Indie,Casual,Sports,Bowling',\n",
       " 'Indie,Action,Pixel Graphics,2D,Retro,Arcade,Score Attack,Minimalist,Comedy,Singleplayer,Fast-Paced,Casual,Funny,Parody,Difficult,Gore,Violent,Western,Controller,Blood',\n",
       " '2D Platformer,Atmospheric,Surreal,Mystery,Puzzle,Survival,Adventure,Linear,Singleplayer,Experimental,Platformer,Precision Platformer,Puzzle-Platformer,2D,Stylized,Physics,Time Manipulation,Casual,Indie',\n",
       " 'Indie,Adventure,Nudity,Violent,Sexual Content,Story Rich',\n",
       " 'Turn-Based Combat,Massively Multiplayer,Multiplayer,RPG,Tactical RPG,Exploration,PvP,MMORPG,Turn-Based Strategy,God Game,Strategy,2.5D,Magic,Medieval,Mythology,Class-Based,Turn-Based Tactics,Singleplayer,Online Co-Op,Co-op']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include only non-null values\n",
    "col_name = 'Tags'\n",
    "col = list(data[col_name].dropna())[:5]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n",
    "# print(list(data[col_name].value_counts()))\n",
    "\n",
    "all_tags = []\n",
    "\n",
    "# apply a function to the values\n",
    "def clean_categories(categories):\n",
    "    if type(categories) is not str:\n",
    "        return []\n",
    "    # print(categories)\n",
    "    return categories.split(\",\")\n",
    "\n",
    "new_df = data[col_name].apply(clean_categories)\n",
    "# merge all the lists into one\n",
    "for categories in new_df:\n",
    "    all_tags.extend(categories)\n",
    "\n",
    "print(len(set(all_tags)))\n",
    "\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  66601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://cdn.akamai.steamstatic.com/steam/apps/256863704/movie_max.mp4?t=1638854607',\n",
       " 'http://cdn.akamai.steamstatic.com/steam/apps/256691108/movie_max.mp4?t=1506089586',\n",
       " 'http://cdn.akamai.steamstatic.com/steam/apps/256847488/movie_max.mp4?t=1635980739,http://cdn.akamai.steamstatic.com/steam/apps/256847487/movie_max.mp4?t=1635980747',\n",
       " 'http://cdn.akamai.steamstatic.com/steam/apps/256819153/movie_max.mp4?t=1611314333',\n",
       " 'http://cdn.akamai.steamstatic.com/steam/apps/256764430/movie_max.mp4?t=1580660973']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include only non-null values\n",
    "col_name = 'Movies'\n",
    "col = list(data[col_name].dropna())[:5]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n",
    "col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  9663\n",
      "134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"['English']\",\n",
       " \"['English', 'French', 'Italian', 'German', 'Spanish - Spain', 'Japanese', 'Portuguese - Brazil', 'Russian', 'Simplified Chinese', 'Traditional Chinese']\",\n",
       " \"['English', 'Portuguese - Brazil']\",\n",
       " \"['English', 'French', 'Italian', 'German', 'Spanish - Spain', 'Japanese', 'Korean', 'Portuguese', 'Russian', 'Simplified Chinese', 'Traditional Chinese']\",\n",
       " \"['English', 'Spanish - Spain']\"]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# include only non-null values\n",
    "col_name = 'Supported languages'\n",
    "col = list(data[col_name].dropna())[:5]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n",
    "\n",
    "all_languages = []\n",
    "\n",
    "# apply a function to the values\n",
    "def clean_languages(categories):\n",
    "    if type(categories) is not str:\n",
    "        return []\n",
    "    # error in the dataset \n",
    "    to_replace = \"K'iche'\"\n",
    "    if to_replace in categories:\n",
    "        categories = categories.replace(to_replace, \"'Kiche'\")\n",
    "    try:\n",
    "        langs = json.loads(categories.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "    except:\n",
    "        print(categories)\n",
    "        raise\n",
    "    return langs\n",
    "\n",
    "new_df = data[col_name].apply(clean_languages)\n",
    "# merge all the lists into one\n",
    "for categories in new_df:\n",
    "    all_languages.extend(categories)\n",
    "\n",
    "print(len(set(all_languages)))\n",
    "\n",
    "col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  1935\n",
      "121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"['English', 'German']\",\n",
       " '[]',\n",
       " \"['English', 'Japanese']\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# include only non-null values\n",
    "col_name = 'Full audio languages'\n",
    "col = list(data[col_name].dropna())[:10]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n",
    "\n",
    "all_languages = []\n",
    "\n",
    "# apply a function to the values\n",
    "def clean_languages(categories):\n",
    "    if type(categories) is not str:\n",
    "        return []\n",
    "    # error in the dataset \n",
    "    to_replace = \"K'iche'\"\n",
    "    if to_replace in categories:\n",
    "        categories = categories.replace(to_replace, \"'Kiche'\")\n",
    "    try:\n",
    "        langs = json.loads(categories.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "    except:\n",
    "        print(categories)\n",
    "        raise\n",
    "    return langs\n",
    "\n",
    "new_df = data[col_name].apply(clean_languages)\n",
    "# merge all the lists into one\n",
    "for categories in new_df:\n",
    "    all_languages.extend(categories)\n",
    "\n",
    "print(len(set(all_languages)))\n",
    "\n",
    "col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hua', K'iche', 'Khmer', 'Konkani', 'Kyrgyz', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malayalam', 'Malay', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Nepali', 'Odia', 'Punjabi (Gurmukhi)', 'Punjabi (Shahmukhi)', 'Kinyarwanda', 'Sinhala', 'Sindhi', 'Slovak', 'Slovenian', 'Sorani', 'Sotho', 'Swahili', 'Serbian', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Tigrinya', 'Tswana', 'Turkmen', 'Urdu', 'Uyghur', 'Valencian', 'Wolof', 'Xhosa', 'Yoruba', 'Zulu', 'Cherokee', 'Uzbek', 'Hebrew', 'Igbo', 'Irish', 'Scots', 'Icelandic']\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"['English', 'French', 'Italian', 'German', 'Spanish - Spain', 'Arabic', 'Simplified Chinese', 'Portuguese - Brazil', 'Bulgarian', 'Danish', 'Dutch', 'Finnish', 'Traditional Chinese', 'Japanese', 'Korean', 'Spanish - Latin America', 'Polish', 'Hungarian', 'Norwegian', 'Portuguese - Portugal', 'Romanian', 'Russian', 'Thai', 'Turkish', 'Ukrainian', 'Vietnamese', 'Greek', 'Czech', 'Swedish', 'Afrikaans', 'Amharic', 'Albanian', 'Assamese', 'Azerbaijani', 'Bangla', 'Basque', 'Belarusian', 'Bosnian', 'Dari', 'Indonesian', 'Armenian', 'Estonian', 'Persian', 'Filipino', 'Welsh', 'Galician', 'Gujarati', 'Georgian', 'Hausa', 'Hindi', 'Croatian', 'Kannada', 'Catalan', 'Kazakh', 'Quechua', K'iche', 'Khmer', 'Konkani', 'Kyrgyz', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malayalam', 'Malay', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Nepali', 'Odia', 'Punjabi (Gurmukhi)', 'Punjabi (Shahmukhi)', 'Kinyarwanda', 'Sinhala', 'Sindhi', 'Slovak', 'Slovenian', 'Sorani', 'Sotho', 'Swahili', 'Serbian', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Tigrinya', 'Tswana', 'Turkmen', 'Urdu', 'Uyghur', 'Valencian', 'Wolof', 'Xhosa', 'Yoruba', 'Zulu', 'Cherokee', 'Uzbek', 'Hebrew', 'Igbo', 'Irish', 'Scots', 'Icelandic']\"[680:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column:  423\n"
     ]
    }
   ],
   "source": [
    "# include only non-null values\n",
    "col_name = 'Achievements'\n",
    "col = list(data[col_name].dropna())[:10]\n",
    "unique_col = data[col_name].nunique()\n",
    "print(\"Unique values in the column: \", unique_col)\n",
    "# show each value and the number of times it appears\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP\n",
    "# drop Header image\n",
    "# drop Score rank. It has 71674 null values (out of 71716!).\n",
    "# probably drop Develops (too many unique values 42615). We can also transform these features to has_experienced_developer (more than 50 games)\n",
    "# probably drop Publishers (too many unique values 36815). We can also transform these features to has_experienced_publisher (more than 50 games)\n",
    "# probably drop Screenshots.\n",
    "# drop AppID\n",
    "# drop Name\n",
    "\n",
    "# TRANSFORM\n",
    "# transform Website to has_website\n",
    "# tranform Support url to has_support_url\n",
    "# transform Support email to has_support_email\n",
    "# transform Metacritic url to has_metacritic_url\n",
    "# transform Categories (unique vals = 40) using one hot encoding and fill missing values (3407).\n",
    "# transform Genres (unique vals = 30) using one hot encoding and fill missing values (2439).\n",
    "# transform Tags (unique vals = 446) using one hot encoding and fill missing values (14014). Or maybe not. Just ignore it.\n",
    "# tranform Movies to num_movies (not sure though. These are NOT actual movies. They are trailers. So, maybe we can ignore this feature.)\n",
    "# Supported languages (unique = 134) one hot encoding\n",
    "# Full audio languages (unique = 121) one hot encoding\n",
    "\n",
    "# KEEP\n",
    "# Price\n",
    "# Required age\n",
    "# Release date\n",
    "# Metacritic score \n",
    "# Achievements\n",
    "\n",
    "\n",
    "# ALL BELOW ARE TEXT\n",
    "# transform About the game to something\n",
    "# tranform Reviews to something\n",
    "# transform Notes to something\n",
    "\n",
    "# TARGET\n",
    "# choose one of the ones below and drop the rest to avoid data leakage\n",
    "# Average playtime forever          \n",
    "# Average playtime two weeks        \n",
    "# Median playtime forever           \n",
    "# Median playtime two weeks   \n",
    "\n",
    "# IDK (but problably drop because leakage)\n",
    "# Estimated owners is of the format (%d - %d)\n",
    "# Peak CCU\n",
    "# User score\n",
    "# Positive\n",
    "# Negative\n",
    "# Recommendations\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71716, 32)\n",
      "Categories 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/hc861b_12cjgmbbb5w4q1jcc0000gn/T/ipykernel_59849/306713549.py:55: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  new_col = df[feat_name].str.contains(category).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres 33\n",
      "Tags 445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/hc861b_12cjgmbbb5w4q1jcc0000gn/T/ipykernel_59849/306713549.py:55: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  new_col = df[feat_name].str.contains(category).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported languages 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/hc861b_12cjgmbbb5w4q1jcc0000gn/T/ipykernel_59849/306713549.py:109: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  new_col = df[feat_name].str.contains(category).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full audio languages 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/hc861b_12cjgmbbb5w4q1jcc0000gn/T/ipykernel_59849/306713549.py:109: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  new_col = df[feat_name].str.contains(category).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54529, 767)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak CCU</th>\n",
       "      <th>Required age</th>\n",
       "      <th>Price</th>\n",
       "      <th>DLC count</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Mac</th>\n",
       "      <th>Linux</th>\n",
       "      <th>Metacritic score</th>\n",
       "      <th>User score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>...</th>\n",
       "      <th>Full audio languages Dutch</th>\n",
       "      <th>Full audio languages Nepali</th>\n",
       "      <th>Full audio languages French&amp;amp;lt;strong&amp;amp;gt;&amp;amp;lt;/strong&amp;amp;gt;</th>\n",
       "      <th>Full audio languages Sindhi</th>\n",
       "      <th>Full audio languages Basque</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>estimated_owner_min</th>\n",
       "      <th>estimated_owner_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>50000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak CCU  Required age  Price  DLC count  Windows  Mac  Linux  \\\n",
       "0         0             0  19.99          0        1    1      1   \n",
       "1         0             0   0.99          0        1    1      1   \n",
       "3         0             0   5.99          0        1    1      1   \n",
       "4         0             0   0.00          0        1    1      1   \n",
       "5        68             0   0.00          0        1    1      1   \n",
       "\n",
       "   Metacritic score  User score  Positive  ...  Full audio languages Dutch  \\\n",
       "0                 0           0         6  ...                           0   \n",
       "1                 0           0        53  ...                           0   \n",
       "3                 0           0         3  ...                           0   \n",
       "4                 0           0        50  ...                           0   \n",
       "5                 0           0        87  ...                           0   \n",
       "\n",
       "   Full audio languages Nepali  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "3                            0   \n",
       "4                            0   \n",
       "5                            0   \n",
       "\n",
       "   Full audio languages French&amp;lt;strong&amp;gt;&amp;lt;/strong&amp;gt;  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "5                                                  0                          \n",
       "\n",
       "   Full audio languages Sindhi  Full audio languages Basque  release_year  \\\n",
       "0                            0                            0          2008   \n",
       "1                            0                            0          2017   \n",
       "3                            0                            0          2020   \n",
       "4                            0                            0          2020   \n",
       "5                            0                            0          2021   \n",
       "\n",
       "   release_month  release_day  estimated_owner_min  estimated_owner_max  \n",
       "0             10           21                    0                20000  \n",
       "1             10           12                    0                20000  \n",
       "3              7           23                    0                20000  \n",
       "4              2            3                    0                20000  \n",
       "5              2           26                50000               100000  \n",
       "\n",
       "[5 rows x 767 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import gc\n",
    "\n",
    "df = data.copy()\n",
    "gc.collect()\n",
    "# DROP\n",
    "# drop Header image\n",
    "# drop Score rank. It has 71674 null values (out of 71716!).\n",
    "# probably drop Develops (too many unique values 42615). We can also transform these features to has_experienced_developer (more than 50 games)\n",
    "# probably drop Publishers (too many unique values 36815). We can also transform these features to has_experienced_publisher (more than 50 games)\n",
    "# probably drop Screenshots.\n",
    "# drop AppID\n",
    "# drop Name\n",
    "\n",
    "df.drop(columns=['Header image', 'Score rank', 'Developers', 'Publishers', 'Screenshots', 'AppID', 'Name'], inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "# TRANSFORM\n",
    "# transform Website to has_website\n",
    "df['has_website'] = df['Website'].notnull().astype(int)\n",
    "df.drop(columns=['Website'], inplace=True)\n",
    "\n",
    "# tranform Support url to has_support_url\n",
    "df['has_support_url'] = df['Support url'].notnull().astype(int)\n",
    "df.drop(columns=['Support url'], inplace=True)\n",
    "\n",
    "# transform Support email to has_support_email\n",
    "df['has_support_email'] = df['Support email'].notnull().astype(int)\n",
    "df.drop(columns=['Support email'], inplace=True)\n",
    "\n",
    "# transform Metacritic url to has_metacritic_url\n",
    "df['has_metacritic_url'] = df['Metacritic url'].notnull().astype(int)\n",
    "df.drop(columns=['Metacritic url'], inplace=True)\n",
    "\n",
    "def clean_cat_feats(df, feat_name, sep=','):\n",
    "    all_categories = []\n",
    "    def clean_categories(categories):\n",
    "        if type(categories) is not str:\n",
    "            return []\n",
    "        return categories.split(sep)\n",
    "\n",
    "    new_df = df[feat_name].apply(clean_categories)\n",
    "    # merge all the lists into one\n",
    "    for categories in new_df:\n",
    "        all_categories.extend(categories)\n",
    "\n",
    "    unique_categories = set(all_categories)\n",
    "    print(feat_name, len(unique_categories))\n",
    "    if len(unique_categories) > 500:\n",
    "        raise ValueError(\"Too many unique values\")\n",
    "    \n",
    "    # create a new column for each category\n",
    "    new_cols = []\n",
    "    for category in unique_categories:\n",
    "        new_col = df[feat_name].str.contains(category).astype(int)\n",
    "        new_cols.append(new_col)\n",
    "    \n",
    "    new_df = pd.concat(new_cols, axis=1)\n",
    "    unique_colums = [feat_name + ' ' + category for category in unique_categories]\n",
    "    new_df.columns = unique_colums\n",
    "    # print(new_df.columns)\n",
    "    # print(new_df.shape)\n",
    "    df = pd.concat([df, new_df], axis=1)\n",
    "    # df.merge(new_df, left_index=True, right_index=True, inplace=True)\n",
    "    \n",
    "    df.drop(columns=[feat_name], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df.dropna(subset=['Categories', 'Genres', 'Tags', 'Movies'], inplace=True)\n",
    "# transform Categories (unique vals = 40) using one hot encoding and fill missing values (3407).\n",
    "df = clean_cat_feats(df, 'Categories')\n",
    "# raise ValueError(\"Too many unique values\")\n",
    "# transform Genres (unique vals = 30) using one hot encoding and fill missing values (2439).\n",
    "df = clean_cat_feats(df, 'Genres')\n",
    "# transform Tags (unique vals = 446) using one hot encoding and fill missing values (14014). Or maybe not. Just ignore it.\n",
    "df = clean_cat_feats(df, 'Tags')\n",
    "# tranform Movies to num_movies (not sure though. These are NOT actual movies. They are trailers. So, maybe we can ignore this feature.)\n",
    "df['num_movies'] = df['Movies'].apply(lambda x: len(x.split(',')))\n",
    "df.drop(columns=['Movies'], inplace=True)\n",
    "\n",
    "def clean_cat_feats_langs(df, feat_name, sep=','):\n",
    "    all_categories = []\n",
    "    def clean_categories(categories):\n",
    "        if type(categories) is not str:\n",
    "            return []\n",
    "        # error in the dataset \n",
    "        to_replace = \"K'iche'\"\n",
    "        if to_replace in categories:\n",
    "            categories = categories.replace(to_replace, \"'Kiche'\")\n",
    "        try:\n",
    "            langs = json.loads(categories.replace(\"'\", \"\\\"\"))\n",
    "        except:\n",
    "            raise\n",
    "        return langs\n",
    "    \n",
    "    new_df = df[feat_name].apply(clean_categories)\n",
    "    # merge all the lists into one\n",
    "    for categories in new_df:\n",
    "        all_categories.extend(categories)\n",
    "\n",
    "    unique_categories = set(all_categories)\n",
    "    print(feat_name, len(unique_categories))\n",
    "\n",
    "    # create a new column for each category\n",
    "    new_cols = []\n",
    "    for category in unique_categories:\n",
    "        try: \n",
    "            new_col = df[feat_name].str.contains(category).astype(int)\n",
    "            new_cols.append(new_col)\n",
    "        except: \n",
    "            print([category])\n",
    "            raise\n",
    "    \n",
    "    new_df = pd.concat(new_cols, axis=1)\n",
    "    unique_colums = [feat_name + ' ' + category for category in unique_categories]\n",
    "    new_df.columns = unique_colums\n",
    "    # print(new_df.columns)\n",
    "    # print(new_df.shape)\n",
    "    df = pd.concat([df, new_df], axis=1)\n",
    "    # df.merge(new_df, left_index=True, right_index=True)\n",
    "\n",
    "    df.drop(columns=[feat_name], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Supported languages (unique = 134) one hot encoding\n",
    "df = clean_cat_feats_langs(df, 'Supported languages')\n",
    "# Full audio languages (unique = 121) one hot encoding\n",
    "df = clean_cat_feats_langs(df, 'Full audio languages')\n",
    "\n",
    "\n",
    "# KEEP\n",
    "# Price\n",
    "# Required age\n",
    "# Release date\n",
    "# extract some useful feats from Release date\n",
    "df['Release date'] = pd.to_datetime(df['Release date'])\n",
    "df['release_year'] = df['Release date'].dt.year\n",
    "df['release_month'] = df['Release date'].dt.month\n",
    "df['release_day'] = df['Release date'].dt.day\n",
    "df.drop(columns=['Release date'], inplace=True)\n",
    "# Metacritic score \n",
    "# Achievements\n",
    "# Windows \n",
    "# to int\n",
    "df['Windows'] = df['Windows'].astype(int)\n",
    "# Mac\n",
    "df['Mac'] = df['Windows'].astype(int)\n",
    "# Linux\n",
    "df['Linux'] = df['Windows'].astype(int)\n",
    "\n",
    "\n",
    "# ALL BELOW ARE TEXT\n",
    "df.drop(columns=['About the game', 'Reviews', 'Notes'], inplace=True)\n",
    "# transform About the game to something\n",
    "# tranform Reviews to something\n",
    "# transform Notes to something\n",
    "\n",
    "# TARGET\n",
    "df.drop(columns=['Average playtime forever', 'Median playtime forever', 'Median playtime two weeks'], inplace=True)\n",
    "# choose one of the ones below and drop the rest to avoid data leakage\n",
    "# Average playtime forever          \n",
    "# Average playtime two weeks        \n",
    "# Median playtime forever           \n",
    "# Median playtime two weeks   \n",
    "\n",
    "# IDK (but problably drop because leakage)\n",
    "# df.dropna(subset=['Average playtime forever', 'Median playtime forever', 'Median playtime two weeks'], inplace=True)\n",
    "# Estimated owners\n",
    "df['estimated_owner_min'] = df['Estimated owners'].apply(lambda x: int(x.split('-')[0].strip()))\n",
    "df['estimated_owner_max'] = df['Estimated owners'].apply(lambda x: int(x.split('-')[1].strip()))\n",
    "df.drop(columns=['Estimated owners'], inplace=True)\n",
    "# Peak CCU\n",
    "# User score\n",
    "# Positive\n",
    "# Negative\n",
    "# Recommendations\n",
    "gc.collect()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Peak CCU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m types \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, typ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cols, types):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m, col\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(typ)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(typ)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m(typ))\n",
      "\u001b[0;31mAssertionError\u001b[0m: Peak CCU"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = df.columns\n",
    "types = df.dtypes\n",
    "for col, typ in zip(cols, types):\n",
    "    assert typ == object, col\n",
    "    if not str(typ).startswith('int') and not str(typ).startswith('float'):\n",
    "        print(col, str(typ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
